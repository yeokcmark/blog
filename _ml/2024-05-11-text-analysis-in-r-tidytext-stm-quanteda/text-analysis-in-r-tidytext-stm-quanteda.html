<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { color: #00769e; background-color: #f1f3f5; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span { color: #00769e; } /* Normal */
code span.al { color: #ad0000; } /* Alert */
code span.an { color: #5e5e5e; } /* Annotation */
code span.at { color: #657422; } /* Attribute */
code span.bn { color: #ad0000; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #00769e; } /* ControlFlow */
code span.ch { color: #20794d; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #5e5e5e; } /* Comment */
code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
code span.dt { color: #ad0000; } /* DataType */
code span.dv { color: #ad0000; } /* DecVal */
code span.er { color: #ad0000; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #ad0000; } /* Float */
code span.fu { color: #4758ab; } /* Function */
code span.im { } /* Import */
code span.in { color: #5e5e5e; } /* Information */
code span.kw { color: #00769e; } /* Keyword */
code span.op { color: #5e5e5e; } /* Operator */
code span.ot { color: #00769e; } /* Other */
code span.pp { color: #ad0000; } /* Preprocessor */
code span.sc { color: #5e5e5e; } /* SpecialChar */
code span.ss { color: #20794d; } /* SpecialString */
code span.st { color: #20794d; } /* String */
code span.va { color: #111111; } /* Variable */
code span.vs { color: #20794d; } /* VerbatimString */
code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
</style>


  <!--radix_placeholder_meta_tags-->
  <title>text analysis in R: tidytext, stm, quanteda</title>

  <meta property="description" itemprop="description" content="I completed Module 5 of my course, which was about Text Classification and Topic Modeling. I wanted to get some practice with what I learnt in class, as well as explore more about the quanteda package."/>


  <!--  https://schema.org/Article -->
  <meta property="article:published" itemprop="datePublished" content="2024-05-11"/>
  <meta property="article:created" itemprop="dateCreated" content="2024-05-11"/>

  <!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
  <meta property="og:title" content="text analysis in R: tidytext, stm, quanteda"/>
  <meta property="og:type" content="article"/>
  <meta property="og:description" content="I completed Module 5 of my course, which was about Text Classification and Topic Modeling. I wanted to get some practice with what I learnt in class, as well as explore more about the quanteda package."/>
  <meta property="og:locale" content="en_US"/>

  <!--  https://dev.twitter.com/cards/types/summary -->
  <meta property="twitter:card" content="summary"/>
  <meta property="twitter:title" content="text analysis in R: tidytext, stm, quanteda"/>
  <meta property="twitter:description" content="I completed Module 5 of my course, which was about Text Classification and Topic Modeling. I wanted to get some practice with what I learnt in class, as well as explore more about the quanteda package."/>

  <!--/radix_placeholder_meta_tags-->
  <!--radix_placeholder_rmarkdown_metadata-->

  <script type="text/json" id="radix-rmarkdown-metadata">
  {"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","date","categories","output","editor_options"]}},"value":[{"type":"character","attributes":{},"value":["text analysis in R: tidytext, stm, quanteda"]},{"type":"character","attributes":{},"value":["I completed Module 5 of my course, which was about Text Classification and Topic Modeling. I wanted to get some practice with what I learnt in class, as well as explore more about the quanteda package.\n"]},{"type":"character","attributes":{},"value":["2024-05-11"]},{"type":"character","attributes":{},"value":["LDA","stm","quanteda","tidytext"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["toc","toc_depth","toc_float","self_contained"]}},"value":[{"type":"logical","attributes":{},"value":[true]},{"type":"integer","attributes":{},"value":[6]},{"type":"logical","attributes":{},"value":[true]},{"type":"logical","attributes":{},"value":[false]}]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["chunk_output_type"]}},"value":[{"type":"character","attributes":{},"value":["console"]}]}]}
  </script>
  <!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["hotel_reviews.csv","text-analysis-in-r-tidytext-stm-quanteda_files/anchor-4.2.2/anchor.min.js","text-analysis-in-r-tidytext-stm-quanteda_files/bowser-1.9.3/bowser.min.js","text-analysis-in-r-tidytext-stm-quanteda_files/distill-2.2.21/template.v2.js","text-analysis-in-r-tidytext-stm-quanteda_files/figure-html5/unnamed-chunk-13-1.png","text-analysis-in-r-tidytext-stm-quanteda_files/figure-html5/unnamed-chunk-19-1.png","text-analysis-in-r-tidytext-stm-quanteda_files/figure-html5/unnamed-chunk-20-1.png","text-analysis-in-r-tidytext-stm-quanteda_files/figure-html5/unnamed-chunk-21-1.png","text-analysis-in-r-tidytext-stm-quanteda_files/figure-html5/unnamed-chunk-22-1.png","text-analysis-in-r-tidytext-stm-quanteda_files/figure-html5/unnamed-chunk-23-1.png","text-analysis-in-r-tidytext-stm-quanteda_files/figure-html5/unnamed-chunk-24-1.png","text-analysis-in-r-tidytext-stm-quanteda_files/figure-html5/unnamed-chunk-25-1.png","text-analysis-in-r-tidytext-stm-quanteda_files/figure-html5/unnamed-chunk-27-1.png","text-analysis-in-r-tidytext-stm-quanteda_files/figure-html5/unnamed-chunk-30-1.png","text-analysis-in-r-tidytext-stm-quanteda_files/header-attrs-2.26/header-attrs.js","text-analysis-in-r-tidytext-stm-quanteda_files/jquery-3.6.0/jquery-3.6.0.js","text-analysis-in-r-tidytext-stm-quanteda_files/jquery-3.6.0/jquery-3.6.0.min.js","text-analysis-in-r-tidytext-stm-quanteda_files/jquery-3.6.0/jquery-3.6.0.min.map","text-analysis-in-r-tidytext-stm-quanteda_files/popper-2.6.0/popper.min.js","text-analysis-in-r-tidytext-stm-quanteda_files/tippy-6.2.7/tippy-bundle.umd.min.js","text-analysis-in-r-tidytext-stm-quanteda_files/tippy-6.2.7/tippy-light-border.css","text-analysis-in-r-tidytext-stm-quanteda_files/tippy-6.2.7/tippy.css","text-analysis-in-r-tidytext-stm-quanteda_files/tippy-6.2.7/tippy.umd.min.js","text-analysis-in-r-tidytext-stm-quanteda_files/webcomponents-2.0.0/webcomponents.js"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
  <!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

  <style type="text/css">

  body {
    background-color: white;
  }

  .pandoc-table {
    width: 100%;
  }

  .pandoc-table>caption {
    margin-bottom: 10px;
  }

  .pandoc-table th:not([align]) {
    text-align: left;
  }

  .pagedtable-footer {
    font-size: 15px;
  }

  d-byline .byline {
    grid-template-columns: 2fr 2fr;
  }

  d-byline .byline h3 {
    margin-block-start: 1.5em;
  }

  d-byline .byline .authors-affiliations h3 {
    margin-block-start: 0.5em;
  }

  .authors-affiliations .orcid-id {
    width: 16px;
    height:16px;
    margin-left: 4px;
    margin-right: 4px;
    vertical-align: middle;
    padding-bottom: 2px;
  }

  d-title .dt-tags {
    margin-top: 1em;
    grid-column: text;
  }

  .dt-tags .dt-tag {
    text-decoration: none;
    display: inline-block;
    color: rgba(0,0,0,0.6);
    padding: 0em 0.4em;
    margin-right: 0.5em;
    margin-bottom: 0.4em;
    font-size: 70%;
    border: 1px solid rgba(0,0,0,0.2);
    border-radius: 3px;
    text-transform: uppercase;
    font-weight: 500;
  }

  d-article table.gt_table td,
  d-article table.gt_table th {
    border-bottom: none;
    font-size: 100%;
  }

  .html-widget {
    margin-bottom: 2.0em;
  }

  .l-screen-inset {
    padding-right: 16px;
  }

  .l-screen .caption {
    margin-left: 10px;
  }

  .shaded {
    background: rgb(247, 247, 247);
    padding-top: 20px;
    padding-bottom: 20px;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }

  .shaded .html-widget {
    margin-bottom: 0;
    border: 1px solid rgba(0, 0, 0, 0.1);
  }

  .shaded .shaded-content {
    background: white;
  }

  .text-output {
    margin-top: 0;
    line-height: 1.5em;
  }

  .hidden {
    display: none !important;
  }

  hr.section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    margin: 0px;
  }


  d-byline {
    border-top: none;
  }

  d-article {
    padding-top: 2.5rem;
    padding-bottom: 30px;
    border-top: none;
  }

  d-appendix {
    padding-top: 30px;
  }

  d-article>p>img {
    width: 100%;
  }

  d-article h2 {
    margin: 1rem 0 1.5rem 0;
  }

  d-article h3 {
    margin-top: 1.5rem;
  }

  d-article iframe {
    border: 1px solid rgba(0, 0, 0, 0.1);
    margin-bottom: 2.0em;
    width: 100%;
  }

  /* Tweak code blocks */

  d-article div.sourceCode code,
  d-article pre code {
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  }

  d-article pre,
  d-article div.sourceCode,
  d-article div.sourceCode pre {
    overflow: auto;
  }

  d-article div.sourceCode {
    background-color: white;
  }

  d-article div.sourceCode pre {
    padding-left: 10px;
    font-size: 12px;
    border-left: 2px solid rgba(0,0,0,0.1);
  }

  d-article pre {
    font-size: 12px;
    color: black;
    background: none;
    margin-top: 0;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;

    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;

    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }

  d-article pre a {
    border-bottom: none;
  }

  d-article pre a:hover {
    border-bottom: none;
    text-decoration: underline;
  }

  d-article details {
    grid-column: text;
    margin-bottom: 0.8em;
  }

  @media(min-width: 768px) {

  d-article pre,
  d-article div.sourceCode,
  d-article div.sourceCode pre {
    overflow: visible !important;
  }

  d-article div.sourceCode pre {
    padding-left: 18px;
    font-size: 14px;
  }

  /* tweak for Pandoc numbered line within distill */
  d-article pre.numberSource code > span {
      left: -2em;
  }

  d-article pre {
    font-size: 14px;
  }

  }

  figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }

  /* CSS for d-contents */

  .d-contents {
    grid-column: text;
    color: rgba(0,0,0,0.8);
    font-size: 0.9em;
    padding-bottom: 1em;
    margin-bottom: 1em;
    padding-bottom: 0.5em;
    margin-bottom: 1em;
    padding-left: 0.25em;
    justify-self: start;
  }

  @media(min-width: 1000px) {
    .d-contents.d-contents-float {
      height: 0;
      grid-column-start: 1;
      grid-column-end: 4;
      justify-self: center;
      padding-right: 3em;
      padding-left: 2em;
    }
  }

  .d-contents nav h3 {
    font-size: 18px;
    margin-top: 0;
    margin-bottom: 1em;
  }

  .d-contents li {
    list-style-type: none
  }

  .d-contents nav > ul {
    padding-left: 0;
  }

  .d-contents ul {
    padding-left: 1em
  }

  .d-contents nav ul li {
    margin-top: 0.6em;
    margin-bottom: 0.2em;
  }

  .d-contents nav a {
    font-size: 13px;
    border-bottom: none;
    text-decoration: none
    color: rgba(0, 0, 0, 0.8);
  }

  .d-contents nav a:hover {
    text-decoration: underline solid rgba(0, 0, 0, 0.6)
  }

  .d-contents nav > ul > li > a {
    font-weight: 600;
  }

  .d-contents nav > ul > li > ul {
    font-weight: inherit;
  }

  .d-contents nav > ul > li > ul > li {
    margin-top: 0.2em;
  }


  .d-contents nav ul {
    margin-top: 0;
    margin-bottom: 0.25em;
  }

  .d-article-with-toc h2:nth-child(2) {
    margin-top: 0;
  }


  /* Figure */

  .figure {
    position: relative;
    margin-bottom: 2.5em;
    margin-top: 1.5em;
  }

  .figure .caption {
    color: rgba(0, 0, 0, 0.6);
    font-size: 12px;
    line-height: 1.5em;
  }

  .figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }

  .figure .caption a {
    color: rgba(0, 0, 0, 0.6);
  }

  .figure .caption b,
  .figure .caption strong, {
    font-weight: 600;
    color: rgba(0, 0, 0, 1.0);
  }

  /* Citations */

  d-article .citation {
    color: inherit;
    cursor: inherit;
  }

  div.hanging-indent{
    margin-left: 1em; text-indent: -1em;
  }

  /* Citation hover box */

  .tippy-box[data-theme~=light-border] {
    background-color: rgba(250, 250, 250, 0.95);
  }

  .tippy-content > p {
    margin-bottom: 0;
    padding: 2px;
  }


  /* Tweak 1000px media break to show more text */

  @media(min-width: 1000px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 16px;
    }

    .grid {
      grid-column-gap: 16px;
    }

    d-article {
      font-size: 1.06rem;
      line-height: 1.7em;
    }
    figure .caption, .figure .caption, figure figcaption {
      font-size: 13px;
    }
  }

  @media(min-width: 1180px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 32px;
    }

    .grid {
      grid-column-gap: 32px;
    }
  }


  /* Get the citation styles for the appendix (not auto-injected on render since
     we do our own rendering of the citation appendix) */

  d-appendix .citation-appendix,
  .d-appendix .citation-appendix {
    font-size: 11px;
    line-height: 15px;
    border-left: 1px solid rgba(0, 0, 0, 0.1);
    padding-left: 18px;
    border: 1px solid rgba(0,0,0,0.1);
    background: rgba(0, 0, 0, 0.02);
    padding: 10px 18px;
    border-radius: 3px;
    color: rgba(150, 150, 150, 1);
    overflow: hidden;
    margin-top: -12px;
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  /* Include appendix styles here so they can be overridden */

  d-appendix {
    contain: layout style;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-top: 60px;
    margin-bottom: 0;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    color: rgba(0,0,0,0.5);
    padding-top: 60px;
    padding-bottom: 48px;
  }

  d-appendix h3 {
    grid-column: page-start / text-start;
    font-size: 15px;
    font-weight: 500;
    margin-top: 1em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.65);
  }

  d-appendix h3 + * {
    margin-top: 1em;
  }

  d-appendix ol {
    padding: 0 0 0 15px;
  }

  @media (min-width: 768px) {
    d-appendix ol {
      padding: 0 0 0 30px;
      margin-left: -30px;
    }
  }

  d-appendix li {
    margin-bottom: 1em;
  }

  d-appendix a {
    color: rgba(0, 0, 0, 0.6);
  }

  d-appendix > * {
    grid-column: text;
  }

  d-appendix > d-footnote-list,
  d-appendix > d-citation-list,
  d-appendix > distill-appendix {
    grid-column: screen;
  }

  /* Include footnote styles here so they can be overridden */

  d-footnote-list {
    contain: layout style;
  }

  d-footnote-list > * {
    grid-column: text;
  }

  d-footnote-list a.footnote-backlink {
    color: rgba(0,0,0,0.3);
    padding-left: 0.5em;
  }



  /* Anchor.js */

  .anchorjs-link {
    /*transition: all .25s linear; */
    text-decoration: none;
    border-bottom: none;
  }
  *:hover > .anchorjs-link {
    margin-left: -1.125em !important;
    text-decoration: none;
    border-bottom: none;
  }

  /* Social footer */

  .social_footer {
    margin-top: 30px;
    margin-bottom: 0;
    color: rgba(0,0,0,0.67);
  }

  .disqus-comments {
    margin-right: 30px;
  }

  .disqus-comment-count {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
    cursor: pointer;
  }

  #disqus_thread {
    margin-top: 30px;
  }

  .article-sharing a {
    border-bottom: none;
    margin-right: 8px;
  }

  .article-sharing a:hover {
    border-bottom: none;
  }

  .sidebar-section.subscribe {
    font-size: 12px;
    line-height: 1.6em;
  }

  .subscribe p {
    margin-bottom: 0.5em;
  }


  .article-footer .subscribe {
    font-size: 15px;
    margin-top: 45px;
  }


  .sidebar-section.custom {
    font-size: 12px;
    line-height: 1.6em;
  }

  .custom p {
    margin-bottom: 0.5em;
  }

  /* Styles for listing layout (hide title) */
  .layout-listing d-title, .layout-listing .d-title {
    display: none;
  }

  /* Styles for posts lists (not auto-injected) */


  .posts-with-sidebar {
    padding-left: 45px;
    padding-right: 45px;
  }

  .posts-list .description h2,
  .posts-list .description p {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  }

  .posts-list .description h2 {
    font-weight: 700;
    border-bottom: none;
    padding-bottom: 0;
  }

  .posts-list h2.post-tag {
    border-bottom: 1px solid rgba(0, 0, 0, 0.2);
    padding-bottom: 12px;
  }
  .posts-list {
    margin-top: 60px;
    margin-bottom: 24px;
  }

  .posts-list .post-preview {
    text-decoration: none;
    overflow: hidden;
    display: block;
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
    padding: 24px 0;
  }

  .post-preview-last {
    border-bottom: none !important;
  }

  .posts-list .posts-list-caption {
    grid-column: screen;
    font-weight: 400;
  }

  .posts-list .post-preview h2 {
    margin: 0 0 6px 0;
    line-height: 1.2em;
    font-style: normal;
    font-size: 24px;
  }

  .posts-list .post-preview p {
    margin: 0 0 12px 0;
    line-height: 1.4em;
    font-size: 16px;
  }

  .posts-list .post-preview .thumbnail {
    box-sizing: border-box;
    margin-bottom: 24px;
    position: relative;
    max-width: 500px;
  }
  .posts-list .post-preview img {
    width: 100%;
    display: block;
  }

  .posts-list .metadata {
    font-size: 12px;
    line-height: 1.4em;
    margin-bottom: 18px;
  }

  .posts-list .metadata > * {
    display: inline-block;
  }

  .posts-list .metadata .publishedDate {
    margin-right: 2em;
  }

  .posts-list .metadata .dt-authors {
    display: block;
    margin-top: 0.3em;
    margin-right: 2em;
  }

  .posts-list .dt-tags {
    display: block;
    line-height: 1em;
  }

  .posts-list .dt-tags .dt-tag {
    display: inline-block;
    color: rgba(0,0,0,0.6);
    padding: 0.3em 0.4em;
    margin-right: 0.2em;
    margin-bottom: 0.4em;
    font-size: 60%;
    border: 1px solid rgba(0,0,0,0.2);
    border-radius: 3px;
    text-transform: uppercase;
    font-weight: 500;
  }

  .posts-list img {
    opacity: 1;
  }

  .posts-list img[data-src] {
    opacity: 0;
  }

  .posts-more {
    clear: both;
  }


  .posts-sidebar {
    font-size: 16px;
  }

  .posts-sidebar h3 {
    font-size: 16px;
    margin-top: 0;
    margin-bottom: 0.5em;
    font-weight: 400;
    text-transform: uppercase;
  }

  .sidebar-section {
    margin-bottom: 30px;
  }

  .categories ul {
    list-style-type: none;
    margin: 0;
    padding: 0;
  }

  .categories li {
    color: rgba(0, 0, 0, 0.8);
    margin-bottom: 0;
  }

  .categories li>a {
    border-bottom: none;
  }

  .categories li>a:hover {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  }

  .categories .active {
    font-weight: 600;
  }

  .categories .category-count {
    color: rgba(0, 0, 0, 0.4);
  }


  @media(min-width: 768px) {
    .posts-list .post-preview h2 {
      font-size: 26px;
    }
    .posts-list .post-preview .thumbnail {
      float: right;
      width: 30%;
      margin-bottom: 0;
    }
    .posts-list .post-preview .description {
      float: left;
      width: 45%;
    }
    .posts-list .post-preview .metadata {
      float: left;
      width: 20%;
      margin-top: 8px;
    }
    .posts-list .post-preview p {
      margin: 0 0 12px 0;
      line-height: 1.5em;
      font-size: 16px;
    }
    .posts-with-sidebar .posts-list {
      float: left;
      width: 75%;
    }
    .posts-with-sidebar .posts-sidebar {
      float: right;
      width: 20%;
      margin-top: 60px;
      padding-top: 24px;
      padding-bottom: 24px;
    }
  }


  /* Improve display for browsers without grid (IE/Edge <= 15) */

  .downlevel {
    line-height: 1.6em;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    margin: 0;
  }

  .downlevel .d-title {
    padding-top: 6rem;
    padding-bottom: 1.5rem;
  }

  .downlevel .d-title h1 {
    font-size: 50px;
    font-weight: 700;
    line-height: 1.1em;
    margin: 0 0 0.5rem;
  }

  .downlevel .d-title p {
    font-weight: 300;
    font-size: 1.2rem;
    line-height: 1.55em;
    margin-top: 0;
  }

  .downlevel .d-byline {
    padding-top: 0.8em;
    padding-bottom: 0.8em;
    font-size: 0.8rem;
    line-height: 1.8em;
  }

  .downlevel .section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
  }

  .downlevel .d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
    padding-top: 1rem;
    padding-bottom: 2rem;
  }


  .downlevel .d-appendix {
    padding-left: 0;
    padding-right: 0;
    max-width: none;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.5);
    padding-top: 40px;
    padding-bottom: 48px;
  }

  .downlevel .footnotes ol {
    padding-left: 13px;
  }

  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
    padding-left: 40px;
    padding-right: 40px;
  }

  @media(min-width: 768px) {
    .downlevel .base-grid,
    .downlevel .distill-header,
    .downlevel .d-title,
    .downlevel .d-abstract,
    .downlevel .d-article,
    .downlevel .d-appendix,
    .downlevel .distill-appendix,
    .downlevel .d-byline,
    .downlevel .d-footnote-list,
    .downlevel .d-citation-list,
    .downlevel .distill-footer,
    .downlevel .appendix-bottom,
    .downlevel .posts-container {
    padding-left: 150px;
    padding-right: 150px;
    max-width: 900px;
  }
  }

  .downlevel pre code {
    display: block;
    border-left: 2px solid rgba(0, 0, 0, .1);
    padding: 0 0 0 20px;
    font-size: 14px;
  }

  .downlevel code, .downlevel pre {
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;

    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;

    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }

  .downlevel .posts-list .post-preview {
    color: inherit;
  }



  </style>

  <script type="application/javascript">

  function is_downlevel_browser() {
    if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                   window.navigator.userAgent)) {
      return true;
    } else {
      return window.load_distill_framework === undefined;
    }
  }

  // show body when load is complete
  function on_load_complete() {

    // add anchors
    if (window.anchors) {
      window.anchors.options.placement = 'left';
      window.anchors.add('d-article > h2, d-article > h3, d-article > h4, d-article > h5');
    }


    // set body to visible
    document.body.style.visibility = 'visible';

    // force redraw for leaflet widgets
    if (window.HTMLWidgets) {
      var maps = window.HTMLWidgets.findAll(".leaflet");
      $.each(maps, function(i, el) {
        var map = this.getMap();
        map.invalidateSize();
        map.eachLayer(function(layer) {
          if (layer instanceof L.TileLayer)
            layer.redraw();
        });
      });
    }

    // trigger 'shown' so htmlwidgets resize
    $('d-article').trigger('shown');
  }

  function init_distill() {

    init_common();

    // create front matter
    var front_matter = $('<d-front-matter></d-front-matter>');
    $('#distill-front-matter').wrap(front_matter);

    // create d-title
    $('.d-title').changeElementType('d-title');

    // separator
    var separator = '<hr class="section-separator" style="clear: both"/>';
    // prepend separator above appendix
    $('.d-byline').before(separator);
    $('.d-article').before(separator);

    // create d-byline
    var byline = $('<d-byline></d-byline>');
    $('.d-byline').replaceWith(byline);

    // create d-article
    var article = $('<d-article></d-article>');
    $('.d-article').wrap(article).children().unwrap();

    // move posts container into article
    $('.posts-container').appendTo($('d-article'));

    // create d-appendix
    $('.d-appendix').changeElementType('d-appendix');

    // flag indicating that we have appendix items
    var appendix = $('.appendix-bottom').children('h3').length > 0;

    // replace footnotes with <d-footnote>
    $('.footnote-ref').each(function(i, val) {
      appendix = true;
      var href = $(this).attr('href');
      var id = href.replace('#', '');
      var fn = $('#' + id);
      var fn_p = $('#' + id + '>p');
      fn_p.find('.footnote-back').remove();
      var text = fn_p.html();
      var dtfn = $('<d-footnote></d-footnote>');
      dtfn.html(text);
      $(this).replaceWith(dtfn);
    });
    // remove footnotes
    $('.footnotes').remove();

    // move refs into #references-listing
    $('#references-listing').replaceWith($('#refs'));

    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      var id = $(this).attr('id');
      $('.d-contents a[href="#' + id + '"]').parent().remove();
      appendix = true;
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
    });

    // show d-appendix if we have appendix content
    $("d-appendix").css('display', appendix ? 'grid' : 'none');

    // localize layout chunks to just output
    $('.layout-chunk').each(function(i, val) {

      // capture layout
      var layout = $(this).attr('data-layout');

      // apply layout to markdown level block elements
      var elements = $(this).children().not('details, div.sourceCode, pre, script');
      elements.each(function(i, el) {
        var layout_div = $('<div class="' + layout + '"></div>');
        if (layout_div.hasClass('shaded')) {
          var shaded_content = $('<div class="shaded-content"></div>');
          $(this).wrap(shaded_content);
          $(this).parent().wrap(layout_div);
        } else {
          $(this).wrap(layout_div);
        }
      });


      // unwrap the layout-chunk div
      $(this).children().unwrap();
    });

    // remove code block used to force  highlighting css
    $('.distill-force-highlighting-css').parent().remove();

    // remove empty line numbers inserted by pandoc when using a
    // custom syntax highlighting theme, except when numbering line
    // in code chunk
    $('pre:not(.numberLines) code.sourceCode a:empty').remove();

    // load distill framework
    load_distill_framework();

    // wait for window.distillRunlevel == 4 to do post processing
    function distill_post_process() {

      if (!window.distillRunlevel || window.distillRunlevel < 4)
        return;

      // hide author/affiliations entirely if we have no authors
      var front_matter = JSON.parse($("#distill-front-matter").html());
      var have_authors = front_matter.authors && front_matter.authors.length > 0;
      if (!have_authors)
        $('d-byline').addClass('hidden');

      // article with toc class
      $('.d-contents').parent().addClass('d-article-with-toc');

      // strip links that point to #
      $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

      // add orcid ids
      $('.authors-affiliations').find('.author').each(function(i, el) {
        var orcid_id = front_matter.authors[i].orcidID;
        var author_name = front_matter.authors[i].author
        if (orcid_id) {
          var a = $('<a></a>');
          a.attr('href', 'https://orcid.org/' + orcid_id);
          var img = $('<img></img>');
          img.addClass('orcid-id');
          img.attr('alt', author_name ? 'ORCID ID for ' + author_name : 'ORCID ID');
          img.attr('src','data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==');
          a.append(img);
          $(this).append(a);
        }
      });

      // hide elements of author/affiliations grid that have no value
      function hide_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
      }

      // affiliations
      var have_affiliations = false;
      for (var i = 0; i<front_matter.authors.length; ++i) {
        var author = front_matter.authors[i];
        if (author.affiliation !== "&nbsp;") {
          have_affiliations = true;
          break;
        }
      }
      if (!have_affiliations)
        $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

      // published date
      if (!front_matter.publishedDate)
        hide_byline_column("Published");

      // document object identifier
      var doi = $('d-byline').find('h3:contains("DOI")');
      var doi_p = doi.next().empty();
      if (!front_matter.doi) {
        // if we have a citation and valid citationText then link to that
        if ($('#citation').length > 0 && front_matter.citationText) {
          doi.html('Citation');
          $('<a href="#citation"></a>')
            .text(front_matter.citationText)
            .appendTo(doi_p);
        } else {
          hide_byline_column("DOI");
        }
      } else {
        $('<a></a>')
           .attr('href', "https://doi.org/" + front_matter.doi)
           .html(front_matter.doi)
           .appendTo(doi_p);
      }

       // change plural form of authors/affiliations
      if (front_matter.authors.length === 1) {
        var grid = $('.authors-affiliations');
        grid.children('h3:contains("Authors")').text('Author');
        grid.children('h3:contains("Affiliations")').text('Affiliation');
      }

      // remove d-appendix and d-footnote-list local styles
      $('d-appendix > style:first-child').remove();
      $('d-footnote-list > style:first-child').remove();

      // move appendix-bottom entries to the bottom
      $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
      $('.appendix-bottom').remove();

      // hoverable references
      $('span.citation[data-cites]').each(function() {
        const citeChild = $(this).children()[0]
        // Do not process if @xyz has been used without escaping and without bibliography activated
        // https://github.com/rstudio/distill/issues/466
        if (citeChild === undefined) return true

        if (citeChild.nodeName == "D-FOOTNOTE") {
          var fn = citeChild
          $(this).html(fn.shadowRoot.querySelector("sup"))
          $(this).id = fn.id
          fn.remove()
        }
        var refs = $(this).attr('data-cites').split(" ");
        var refHtml = refs.map(function(ref) {
          // Could use CSS.escape too here, we insure backward compatibility in navigator
          return "<p>" + $('div[id="ref-' + ref + '"]').html() + "</p>";
        }).join("\n");
        window.tippy(this, {
          allowHTML: true,
          content: refHtml,
          maxWidth: 500,
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start'
        });
      });

      // fix footnotes in tables (#411)
      // replacing broken distill.pub feature
      $('table d-footnote').each(function() {
        // we replace internal showAtNode methode which is triggered when hovering a footnote
        this.hoverBox.showAtNode = function(node) {
          // ported from https://github.com/distillpub/template/pull/105/files
          calcOffset = function(elem) {
              let x = elem.offsetLeft;
              let y = elem.offsetTop;
              // Traverse upwards until an `absolute` element is found or `elem`
              // becomes null.
              while (elem = elem.offsetParent && elem.style.position != 'absolute') {
                  x += elem.offsetLeft;
                  y += elem.offsetTop;
              }

              return { left: x, top: y };
          }
          // https://developer.mozilla.org/en-US/docs/Web/API/HTMLElement/offsetTop
          const bbox = node.getBoundingClientRect();
          const offset = calcOffset(node);
          this.show([offset.left + bbox.width, offset.top + bbox.height]);
        }
      })

      // clear polling timer
      clearInterval(tid);

      // show body now that everything is ready
      on_load_complete();
    }

    var tid = setInterval(distill_post_process, 50);
    distill_post_process();

  }

  function init_downlevel() {

    init_common();

     // insert hr after d-title
    $('.d-title').after($('<hr class="section-separator"/>'));

    // check if we have authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;

    // manage byline/border
    if (!have_authors)
      $('.d-byline').remove();
    $('.d-byline').after($('<hr class="section-separator"/>'));
    $('.d-byline a').remove();

    // remove toc
    $('.d-contents').remove();

    // move appendix elements
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
    });


    // inject headers into references and footnotes
    var refs_header = $('<h3></h3>');
    refs_header.text('References');
    $('#refs').prepend(refs_header);

    var footnotes_header = $('<h3></h3');
    footnotes_header.text('Footnotes');
    $('.footnotes').children('hr').first().replaceWith(footnotes_header);

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // remove appendix if it's empty
    if ($('.d-appendix').children().length === 0)
      $('.d-appendix').remove();

    // prepend separator above appendix
    $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

    // trim code
    $('pre>code').each(function(i, val) {
      $(this).html($.trim($(this).html()));
    });

    // move posts-container right before article
    $('.posts-container').insertBefore($('.d-article'));

    $('body').addClass('downlevel');

    on_load_complete();
  }


  function init_common() {

    // jquery plugin to change element types
    (function($) {
      $.fn.changeElementType = function(newType) {
        var attrs = {};

        $.each(this[0].attributes, function(idx, attr) {
          attrs[attr.nodeName] = attr.nodeValue;
        });

        this.replaceWith(function() {
          return $("<" + newType + "/>", attrs).append($(this).contents());
        });
      };
    })(jQuery);

    // prevent underline for linked images
    $('a > img').parent().css({'border-bottom' : 'none'});

    // mark non-body figures created by knitr chunks as 100% width
    $('.layout-chunk').each(function(i, val) {
      var figures = $(this).find('img, .html-widget');
      // ignore leaflet img layers (#106)
      figures = figures.filter(':not(img[class*="leaflet"])')
      if ($(this).attr('data-layout') !== "l-body") {
        figures.css('width', '100%');
      } else {
        figures.css('max-width', '100%');
        figures.filter("[width]").each(function(i, val) {
          var fig = $(this);
          fig.css('width', fig.attr('width') + 'px');
        });

      }
    });

    // auto-append index.html to post-preview links in file: protocol
    // and in rstudio ide preview
    $('.post-preview').each(function(i, val) {
      if (window.location.protocol === "file:")
        $(this).attr('href', $(this).attr('href') + "index.html");
    });

    // get rid of index.html references in header
    if (window.location.protocol !== "file:") {
      $('.distill-site-header a[href]').each(function(i,val) {
        $(this).attr('href', $(this).attr('href').replace(/^index[.]html/, "./"));
      });
    }

    // add class to pandoc style tables
    $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
    $('.kable-table').children('table').addClass('pandoc-table');

    // add figcaption style to table captions
    $('caption').parent('table').addClass("figcaption");

    // initialize posts list
    if (window.init_posts_list)
      window.init_posts_list();

    // implmement disqus comment link
    $('.disqus-comment-count').click(function() {
      window.headroom_prevent_pin = true;
      $('#disqus_thread').toggleClass('hidden');
      if (!$('#disqus_thread').hasClass('hidden')) {
        var offset = $(this).offset();
        $(window).resize();
        $('html, body').animate({
          scrollTop: offset.top - 35
        });
      }
    });
  }

  document.addEventListener('DOMContentLoaded', function() {
    if (is_downlevel_browser())
      init_downlevel();
    else
      window.addEventListener('WebComponentsReady', init_distill);
  });

  </script>

  <!--/radix_placeholder_distill-->
  <script src="text-analysis-in-r-tidytext-stm-quanteda_files/header-attrs-2.26/header-attrs.js"></script>
  <script src="text-analysis-in-r-tidytext-stm-quanteda_files/jquery-3.6.0/jquery-3.6.0.min.js"></script>
  <script src="text-analysis-in-r-tidytext-stm-quanteda_files/popper-2.6.0/popper.min.js"></script>
  <link href="text-analysis-in-r-tidytext-stm-quanteda_files/tippy-6.2.7/tippy.css" rel="stylesheet" />
  <link href="text-analysis-in-r-tidytext-stm-quanteda_files/tippy-6.2.7/tippy-light-border.css" rel="stylesheet" />
  <script src="text-analysis-in-r-tidytext-stm-quanteda_files/tippy-6.2.7/tippy.umd.min.js"></script>
  <script src="text-analysis-in-r-tidytext-stm-quanteda_files/anchor-4.2.2/anchor.min.js"></script>
  <script src="text-analysis-in-r-tidytext-stm-quanteda_files/bowser-1.9.3/bowser.min.js"></script>
  <script src="text-analysis-in-r-tidytext-stm-quanteda_files/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="text-analysis-in-r-tidytext-stm-quanteda_files/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
  <!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"text analysis in R: tidytext, stm, quanteda","description":"I completed Module 5 of my course, which was about Text Classification and Topic Modeling. I wanted to get some practice with what I learnt in class, as well as explore more about the quanteda package.","authors":[],"publishedDate":"2024-05-11T00:00:00.000+08:00"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>text analysis in R: tidytext, stm, quanteda</h1>

<!--radix_placeholder_categories-->
<div class="dt-tags">
<div class="dt-tag">LDA</div>
<div class="dt-tag">stm</div>
<div class="dt-tag">quanteda</div>
<div class="dt-tag">tidytext</div>
</div>
<!--/radix_placeholder_categories-->
<p><p>I completed Module 5 of my course, which was about Text Classification and Topic Modeling. I wanted to get some practice with what I learnt in class, as well as explore more about the quanteda package.</p></p>
</div>


<div class="d-article">
<div class="d-contents d-contents-float">
<nav class="l-text toc figcaption" id="TOC">
<h3>Contents</h3>
<ul>
<li><a href="#introduction" id="toc-introduction">Introduction</a></li>
<li><a href="#group-assignment-question" id="toc-group-assignment-question">Group Assignment Question</a></li>
<li><a href="#set-dependencies-and-import-data" id="toc-set-dependencies-and-import-data">Set dependencies and import data</a></li>
<li><a href="#import-text-data" id="toc-import-text-data">Import text data</a></li>
<li><a href="#topic-modeling-lda-using-tidymodels-and-textminer" id="toc-topic-modeling-lda-using-tidymodels-and-textminer">Topic Modeling (LDA) using Tidymodels and textmineR</a></li>
<li><a href="#topic-modeling-using-stm" id="toc-topic-modeling-using-stm">Topic Modeling using stm::</a></li>
<li><a href="#topic-modeling-using-quanteda" id="toc-topic-modeling-using-quanteda">Topic Modeling using quanteda</a></li>
</ul>
</nav>
</div>
<div class="layout-chunk" data-layout="l-body">
<style type="text/css">
d-byline {
  display: none;
  margin:0;
}

</style>
</div>
<h3 id="introduction">Introduction</h3>
<p>It’s been a while since I updated this blog. And I must admit, the previous article featuring what I did for my first Kaggle competition was a “half-hearted” effort at best.</p>
<p>I completed Module 5 of my coursework at SMU, where we learnt about Text Classification and Topic Modeling. As usual, there was so much to learn over the 4 sessions and so much information to process. However, of late, I’ve had this nagging feeling that I’m only scratching the surface in terms of knowledge - the more I learn, the less I know - what a strange way to feel.</p>
<p>So, I decided to supplement my knowledge by learning more about <code>stm</code> and <code>quanteda</code>. As part of Module 5, we had to complete a group assignment. I shall replicate solutions to one of those questions using <code>lda</code>, <code>stm</code> and <code>quanteda</code>.</p>
<h3 id="group-assignment-question">Group Assignment Question</h3>
<p><em>Now imagine you work as a data scientist for a hotel chain. You receive a dataset from hotels in the US. Your job is to identify the major discussion pointers in customer reviews of the hotel. Find a reliable and valid set of topics, based on prevalence and coherence metrics.</em></p>
<p>That was Question 3 of the group assignment. Now let’s begin by importing the necessary packages and dependencies.</p>
<h3 id="set-dependencies-and-import-data">Set dependencies and import data</h3>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='fu'><a href='https://rdrr.io/r/base/rm.html'>rm</a></span><span class='op'>(</span>list <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/ls.html'>ls</a></span><span class='op'>(</span><span class='op'>)</span><span class='op'>)</span></span>
<span><span class='fu'>pacman</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/pkg/pacman/man/p_load.html'>p_load</a></span><span class='op'>(</span><span class='va'>tidyverse</span>, <span class='va'>stringi</span>,<span class='co'># tidy DS</span></span>
<span>               <span class='va'>skimr</span>, <span class='va'>Hmisc</span>, <span class='va'>broom</span>, <span class='va'>modelr</span>, <span class='co'># EDA 1</span></span>
<span>               <span class='va'>scales</span>, <span class='va'>ggthemes</span>, <span class='va'>gridExtra</span>, <span class='co'># ggplot2::</span></span>
<span>               <span class='va'>DT</span>, <span class='co'># for interactive data display</span></span>
<span>               <span class='va'>doParallel</span>,</span>
<span>               <span class='va'>tidytext</span>, <span class='va'>textrecipes</span>, <span class='va'>lubridate</span>, <span class='va'>tokenizers</span>, <span class='va'>textmineR</span>,</span>
<span>               <span class='va'>stm</span>, <span class='va'>igraph</span>, <span class='va'>stmCorrViz</span>, <span class='va'>huge</span>,</span>
<span>               <span class='va'>quanteda</span>, <span class='va'>readtext</span>, <span class='va'>spacyr</span>, <span class='va'>seededlda</span><span class='op'>)</span></span>
<span><span class='fu'><a href='https://rdrr.io/r/base/load.html'>load</a></span><span class='op'>(</span><span class='st'>"hotel_reviews.Rdata"</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<h3 id="import-text-data">Import text data</h3>
<p>Let’s begin by importing our text data.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>df</span> <span class='op'>&lt;-</span> <span class='fu'>read_csv</span><span class='op'>(</span><span class='st'>"hotel_reviews.csv"</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<p>The dataset consists of 12293 customer reviews, with 2 columns: <code>date</code> and <code>review</code>. Let’s proceed by working on the text using Latent Dirichlet Allocation (LDA). I will use the tidymodels framework for “cleaning” and tokenizing the review data.</p>
<h3 id="topic-modeling-lda-using-tidymodels-and-textminer">Topic Modeling (LDA) using Tidymodels and textmineR</h3>
<p>I will use the tidymodels framework for “cleaning” the text. Let’s start by removing stopword and punctuation. In <code>step_tokenize</code> punctuation and lowercase conversions are default. But for good practice, I will specify them anyway.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>text_lda</span> <span class='op'>&lt;-</span></span>
<span>  <span class='fu'>recipe</span><span class='op'>(</span>formula <span class='op'>=</span> <span class='op'>~</span><span class='va'>.</span>,</span>
<span>         data <span class='op'>=</span> <span class='va'>df</span><span class='op'>)</span> <span class='op'>%&gt;%</span> </span>
<span>  <span class='fu'>step_tokenize</span><span class='op'>(</span><span class='va'>review</span>,</span>
<span>                options <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/list.html'>list</a></span><span class='op'>(</span>strip_punct <span class='op'>=</span> <span class='cn'>TRUE</span>,</span>
<span>                               lowercase <span class='op'>=</span> <span class='cn'>TRUE</span><span class='op'>)</span>,</span>
<span>                token <span class='op'>=</span> <span class='st'>"words"</span> <span class='co'># this is the default</span></span>
<span>                <span class='op'>)</span> <span class='op'>%&gt;%</span> </span>
<span>  <span class='fu'>step_stopwords</span><span class='op'>(</span><span class='va'>review</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<p>Let’s take a look at the output.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>output_text_lda</span><span class='op'>&lt;-</span></span>
<span>  <span class='va'>text_lda</span> <span class='op'>%&gt;%</span> <span class='fu'>prep</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>juice</span><span class='op'>(</span><span class='op'>)</span></span>
<span><span class='va'>output_text_lda</span></span></code></pre>
</div>
<pre><code># A tibble: 12,293 × 2
   date            review
   &lt;fct&gt;        &lt;tknlist&gt;
 1 2-Aug-18   [34 tokens]
 2 27-May-18 [117 tokens]
 3 2-Aug-18   [28 tokens]
 4 2-Aug-18   [66 tokens]
 5 2-Aug-18   [84 tokens]
 6 2-Aug-18   [52 tokens]
 7 1-Aug-18   [26 tokens]
 8 1-Aug-18  [127 tokens]
 9 1-Aug-18   [41 tokens]
10 1-Aug-18  [365 tokens]
# ℹ 12,283 more rows</code></pre>
</div>
<p>We see that “document” or review 1 has 34 tokens, while document 2 has 117 tokens. Let’s compare the actual review to the tokenized output for document 3.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>df</span><span class='op'>$</span><span class='va'>review</span><span class='op'>[</span><span class='fl'>3</span><span class='op'>]</span>;<span class='va'>text_lda</span> <span class='op'>%&gt;%</span> <span class='fu'>prep</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'>juice</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='va'>.</span><span class='op'>[</span><span class='fl'>3</span>,<span class='fl'>2</span><span class='op'>]</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/base/unlist.html'>unlist</a></span><span class='op'>(</span><span class='op'>)</span></span></code></pre>
</div>
<pre><code>[1] &quot;Awesome place, attentive and friendly staff, stunning views. Plenty of choices for food, reasonable to expensive but it is Hawaii and nothing is cheap. Close to many local attractions. Very kid friendly and offers a retreat for parents looking for so.e quiet time.&quot;</code></pre>
<pre><code> review.tokens1  review.tokens2  review.tokens3  review.tokens4 
      &quot;awesome&quot;         &quot;place&quot;     &quot;attentive&quot;      &quot;friendly&quot; 
 review.tokens5  review.tokens6  review.tokens7  review.tokens8 
        &quot;staff&quot;      &quot;stunning&quot;         &quot;views&quot;        &quot;plenty&quot; 
 review.tokens9 review.tokens10 review.tokens11 review.tokens12 
      &quot;choices&quot;          &quot;food&quot;    &quot;reasonable&quot;     &quot;expensive&quot; 
review.tokens13 review.tokens14 review.tokens15 review.tokens16 
       &quot;hawaii&quot;       &quot;nothing&quot;         &quot;cheap&quot;         &quot;close&quot; 
review.tokens17 review.tokens18 review.tokens19 review.tokens20 
         &quot;many&quot;         &quot;local&quot;   &quot;attractions&quot;           &quot;kid&quot; 
review.tokens21 review.tokens22 review.tokens23 review.tokens24 
     &quot;friendly&quot;        &quot;offers&quot;       &quot;retreat&quot;       &quot;parents&quot; 
review.tokens25 review.tokens26 review.tokens27 review.tokens28 
      &quot;looking&quot;          &quot;so.e&quot;         &quot;quiet&quot;          &quot;time&quot; </code></pre>
</div>
<p>We see that stopword such as “and”, “is” as well as punctuations such as “.” and “,” have been removed. Notice that token#26 “so.e” is likely a spelling mistake; its probably meant to be “some”.</p>
<p>Let’s combine the tokens back into sentences without stopword and punctuation, before passing it to <code>CreateDtm</code> from the <code>textmineR</code> package.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>text_lda</span><span class='op'>&lt;-</span></span>
<span>  <span class='va'>text_lda</span> <span class='op'>%&gt;%</span> </span>
<span>  <span class='fu'>step_untokenize</span><span class='op'>(</span><span class='va'>review</span><span class='op'>)</span> <span class='op'>%&gt;%</span> </span>
<span>  <span class='fu'>prep</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span> </span>
<span>  <span class='fu'>juice</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span> </span>
<span>  <span class='fu'>rowid_to_column</span><span class='op'>(</span><span class='st'>"id"</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>text_lda</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/base/print.html'>print</a></span><span class='op'>(</span>n<span class='op'>=</span><span class='fl'>5</span><span class='op'>)</span></span></code></pre>
</div>
<pre><code># A tibble: 12,293 × 3
     id date      review                                              
  &lt;int&gt; &lt;fct&gt;     &lt;fct&gt;                                               
1     1 2-Aug-18  stayed 7 nights 3 year old son decor hotel little o…
2     2 27-May-18 stayed ali tower nice stay proximity beach great pr…
3     3 2-Aug-18  awesome place attentive friendly staff stunning vie…
4     4 2-Aug-18  made reservation december celebrate 50th wedding an…
5     5 2-Aug-18  arrived hotel 4 30pm local time hundreds people che…
# ℹ 12,288 more rows</code></pre>
</div>
<p>Now, we have reviews without stopword and punctuation. CreateDtm is a function within the textmineR package that creates a document term matrix from a character vector. Let’s create a document term matrix for our reviews.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>lda_dtm</span> <span class='op'>&lt;-</span></span>
<span>  <span class='va'>text_lda</span> <span class='op'>%&gt;%</span> </span>
<span>  <span class='fu'>textmineR</span><span class='fu'>::</span><span class='fu'><a href='https://www.rtextmineR.com/reference/CreateDtm.html'>CreateDtm</a></span><span class='op'>(</span>doc_name <span class='op'>=</span> <span class='va'>text_lda</span><span class='op'>$</span><span class='va'>id</span>,</span>
<span>                       doc_vec <span class='op'>=</span> <span class='va'>text_lda</span><span class='op'>$</span><span class='va'>review</span>,</span>
<span>                       ngram_window <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>1</span>,<span class='fl'>2</span><span class='op'>)</span>, <span class='co'># we will create bi-grams, save computational resource</span></span>
<span>                       verbose <span class='op'>=</span> <span class='cn'>TRUE</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<p>Let’s fit and LDA model using <code>FitLdaModel</code> from the textmineR package. Let’s choose 10 topics to start with.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='fu'>doParallel</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/pkg/doParallel/man/registerDoParallel.html'>registerDoParallel</a></span><span class='op'>(</span><span class='op'>)</span></span>
<span><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>240511</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>lda_model</span> <span class='op'>&lt;-</span></span>
<span>  <span class='fu'>FitLdaModel</span><span class='op'>(</span>dtm <span class='op'>=</span> <span class='va'>lda_dtm</span>,</span>
<span>              k <span class='op'>=</span> <span class='fl'>10</span>, <span class='co'># the number of topics</span></span>
<span>              iterations <span class='op'>=</span> <span class='fl'>1000</span>, <span class='co'># number of iterations</span></span>
<span>              calc_r2 <span class='op'>=</span> <span class='cn'>T</span>, <span class='co'># goodness of fit(r square)</span></span>
<span>              beta <span class='op'>=</span> <span class='fl'>0.05</span>,</span>
<span>              alpha <span class='op'>=</span> <span class='fl'>0.10</span>,</span>
<span>              optimize_alpha <span class='op'>=</span> <span class='cn'>T</span>,</span>
<span>              <span class='co'># print performance metrics</span></span>
<span>              calc_coherence <span class='op'>=</span> <span class='cn'>T</span>,</span>
<span>              calc_likelihood <span class='op'>=</span> <span class='cn'>T</span>,</span>
<span>              burnin <span class='op'>=</span> <span class='fl'>200</span></span>
<span>  <span class='op'>)</span></span></code></pre>
</div>
</div>
<p>The lda_model took about 60 minutes to train. That’s slow! Let’s take a look at the top 10 terms for each topic. <em>phi</em> denotes word(term) distribution for each topic.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>lda_model</span><span class='op'>$</span><span class='va'>top10_terms</span> <span class='op'>&lt;-</span></span>
<span>  <span class='fu'>GetTopTerms</span><span class='op'>(</span>phi <span class='op'>=</span> <span class='va'>lda_model</span><span class='op'>$</span><span class='va'>phi</span>,  M <span class='op'>=</span> <span class='fl'>10</span><span class='op'>)</span></span>
<span><span class='va'>lda_model</span><span class='op'>$</span><span class='va'>top10_terms</span></span></code></pre>
</div>
<pre><code>      t_1       t_2         t_3         t_4     t_5         
 [1,] &quot;check&quot;   &quot;food&quot;      &quot;great&quot;     &quot;room&quot;  &quot;room&quot;      
 [2,] &quot;line&quot;    &quot;beach&quot;     &quot;staff&quot;     &quot;us&quot;    &quot;resort&quot;    
 [3,] &quot;get&quot;     &quot;day&quot;       &quot;stay&quot;      &quot;hotel&quot; &quot;day&quot;       
 [4,] &quot;long&quot;    &quot;also&quot;      &quot;hilton&quot;    &quot;told&quot;  &quot;fee&quot;       
 [5,] &quot;room&quot;    &quot;breakfast&quot; &quot;hotel&quot;     &quot;desk&quot;  &quot;per&quot;       
 [6,] &quot;people&quot;  &quot;get&quot;       &quot;resort&quot;    &quot;asked&quot; &quot;resort_fee&quot;
 [7,] &quot;one&quot;     &quot;good&quot;      &quot;village&quot;   &quot;went&quot;  &quot;charge&quot;    
 [8,] &quot;wait&quot;    &quot;go&quot;        &quot;hawaiian&quot;  &quot;got&quot;   &quot;pay&quot;       
 [9,] &quot;t&quot;       &quot;can&quot;       &quot;beautiful&quot; &quot;said&quot;  &quot;hotel&quot;     
[10,] &quot;minutes&quot; &quot;bar&quot;       &quot;friendly&quot;  &quot;back&quot;  &quot;free&quot;      
      t_6           t_7                t_8       t_9     
 [1,] &quot;beach&quot;       &quot;hilton&quot;           &quot;pool&quot;    &quot;hotel&quot; 
 [2,] &quot;hotel&quot;       &quot;hawaiian&quot;         &quot;tower&quot;   &quot;place&quot; 
 [3,] &quot;waikiki&quot;     &quot;property&quot;         &quot;ali&quot;     &quot;like&quot;  
 [4,] &quot;restaurants&quot; &quot;village&quot;          &quot;i&quot;       &quot;people&quot;
 [5,] &quot;resort&quot;      &quot;stay&quot;             &quot;ali_i&quot;   &quot;nice&quot;  
 [6,] &quot;great&quot;       &quot;hawaiian_village&quot; &quot;i_tower&quot; &quot;just&quot;  
 [7,] &quot;shopping&quot;    &quot;time&quot;             &quot;kids&quot;    &quot;beach&quot; 
 [8,] &quot;walk&quot;        &quot;hilton_hawaiian&quot;  &quot;area&quot;    &quot;good&quot;  
 [9,] &quot;shops&quot;       &quot;one&quot;              &quot;pools&quot;   &quot;resort&quot;
[10,] &quot;pools&quot;       &quot;years&quot;            &quot;water&quot;   &quot;really&quot;
      t_10           
 [1,] &quot;room&quot;         
 [2,] &quot;view&quot;         
 [3,] &quot;tower&quot;        
 [4,] &quot;ocean&quot;        
 [5,] &quot;rainbow&quot;      
 [6,] &quot;rainbow_tower&quot;
 [7,] &quot;floor&quot;        
 [8,] &quot;ocean_view&quot;   
 [9,] &quot;stayed&quot;       
[10,] &quot;diamond&quot;      </code></pre>
</div>
<p>We can also take a look at <em>theta</em>, which gives you an understanding of the topic distribution for each document.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>lda_model</span><span class='op'>$</span><span class='va'>theta</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/utils/head.html'>head</a></span><span class='op'>(</span><span class='op'>)</span></span></code></pre>
</div>
<pre><code>          t_1          t_2          t_3          t_4          t_5
1 0.001666667 0.0016666667 0.2683333333 0.0016666667 0.0183333333
2 0.021794872 0.0132478632 0.0816239316 0.0004273504 0.0004273504
3 0.001785714 0.0196428571 0.4839285714 0.0017857143 0.0017857143
4 0.086046512 0.0007751938 0.0007751938 0.6829457364 0.0317829457
5 0.344171779 0.0006134969 0.0006134969 0.0128834356 0.2521472393
6 0.555454545 0.1645454545 0.0009090909 0.1463636364 0.0009090909
           t_6          t_7          t_8          t_9         t_10
1 0.4016666667 0.0016666667 0.1350000000 0.1016666667 0.0683333333
2 0.3209401709 0.0004273504 0.3465811966 0.1756410256 0.0388888889
3 0.4303571429 0.0017857143 0.0017857143 0.0553571429 0.0017857143
4 0.0007751938 0.1945736434 0.0007751938 0.0007751938 0.0007751938
5 0.1601226994 0.0006134969 0.0006134969 0.0558282209 0.1723926380
6 0.0009090909 0.1190909091 0.0009090909 0.0100000000 0.0009090909</code></pre>
</div>
<p>If we take a <code>Colsum</code> along each topic, we can get an understanding of the distribution of each topic across all documents. ie: prevalence</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>lda_model</span><span class='op'>$</span><span class='va'>prevalence</span> <span class='op'>&lt;-</span></span>
<span>  <span class='fu'><a href='https://rdrr.io/r/base/colSums.html'>colSums</a></span><span class='op'>(</span><span class='va'>lda_model</span><span class='op'>$</span><span class='va'>theta</span> <span class='op'>/</span> <span class='fu'><a href='https://rdrr.io/r/base/sum.html'>sum</a></span><span class='op'>(</span><span class='va'>lda_model</span><span class='op'>$</span><span class='va'>theta</span><span class='op'>)</span> <span class='op'>*</span><span class='fl'>100</span><span class='op'>)</span></span>
<span><span class='va'>lda_model</span><span class='op'>$</span><span class='va'>prevalence</span></span></code></pre>
</div>
<pre><code>      t_1       t_2       t_3       t_4       t_5       t_6       t_7 
 5.982809  7.455445 18.512571  7.272022  7.210894 16.891251  6.428908 
      t_8       t_9      t_10 
 6.538578 11.377837 12.329684 </code></pre>
</div>
<p>We can use ggplot to take a look at this distribution.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>lda_model</span><span class='op'>$</span><span class='va'>prevalence</span> <span class='op'>%&gt;%</span> </span>
<span>  <span class='fu'>as_tibble</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span> </span>
<span>  <span class='fu'>rowid_to_column</span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span> </span>
<span>  <span class='fu'>ggplot</span><span class='op'>(</span><span class='fu'>aes</span><span class='op'>(</span>x <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/factor.html'>as.factor</a></span><span class='op'>(</span><span class='va'>rowid</span><span class='op'>)</span>,</span>
<span>             y <span class='op'>=</span> <span class='va'>value</span><span class='op'>)</span></span>
<span>         <span class='op'>)</span> <span class='op'>+</span></span>
<span>  <span class='fu'>geom_col</span><span class='op'>(</span>fill <span class='op'>=</span> <span class='st'>"deepskyblue"</span><span class='op'>)</span><span class='op'>+</span></span>
<span>  <span class='fu'>geom_text</span><span class='op'>(</span><span class='fu'>aes</span><span class='op'>(</span>label <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/Round.html'>round</a></span><span class='op'>(</span><span class='va'>value</span>,<span class='fl'>1</span><span class='op'>)</span><span class='op'>)</span>,</span>
<span>            size <span class='op'>=</span> <span class='fl'>3</span><span class='op'>)</span><span class='op'>+</span></span>
<span>  <span class='fu'>labs</span><span class='op'>(</span>x <span class='op'>=</span> <span class='st'>"Topics 1 to 10"</span>,</span>
<span>       y <span class='op'>=</span> <span class='st'>"Prevalence"</span>,</span>
<span>       title <span class='op'>=</span> <span class='st'>"Prevalence by Topic"</span><span class='op'>)</span><span class='op'>+</span></span>
<span>  <span class='fu'>theme_bw</span><span class='op'>(</span><span class='op'>)</span></span></code></pre>
</div>
<p><img src="text-analysis-in-r-tidytext-stm-quanteda_files/figure-html5/unnamed-chunk-13-1.png" width="576" /></p>
</div>
<p>We can see that topics 3 and 6 are popularly discussed among all reviews. Let’s see the top 10 terms for topic 3 and 6 again.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>lda_model</span><span class='op'>$</span><span class='va'>top10_terms</span><span class='op'>[</span>,<span class='fl'>3</span><span class='op'>]</span>;<span class='va'>lda_model</span><span class='op'>$</span><span class='va'>top10_terms</span><span class='op'>[</span>,<span class='fl'>6</span><span class='op'>]</span></span></code></pre>
</div>
<pre><code> [1] &quot;great&quot;     &quot;staff&quot;     &quot;stay&quot;      &quot;hilton&quot;    &quot;hotel&quot;    
 [6] &quot;resort&quot;    &quot;village&quot;   &quot;hawaiian&quot;  &quot;beautiful&quot; &quot;friendly&quot; </code></pre>
<pre><code> [1] &quot;beach&quot;       &quot;hotel&quot;       &quot;waikiki&quot;     &quot;restaurants&quot;
 [5] &quot;resort&quot;      &quot;great&quot;       &quot;shopping&quot;    &quot;walk&quot;       
 [9] &quot;shops&quot;       &quot;pools&quot;      </code></pre>
</div>
<p>From my guess, the Hilton hotel in Waikiki, Hawaii is a beautiful resort hotel, with great, friendly staff. The guests enjoyed its restaurants, pool, and shopping during their stay.</p>
<p>There is still a lot more that we can explore, but I’m going to leave LDA for now, and process the same text using <code>stm</code> and see what insights we can discover.</p>
<h3 id="topic-modeling-using-stm">Topic Modeling using stm::</h3>
<p>The stm package has its own text processor, aptly named textProcessor(). I will make use of it to process the text. Thereafter, let’s examine the output for document 3 again. I will also create a new feature “month” for use as metadata.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='co'># engineer a new feature month_name.</span></span>
<span><span class='va'>df_stm</span> <span class='op'>&lt;-</span></span>
<span>  <span class='va'>df</span> <span class='op'>%&gt;%</span> </span>
<span>  <span class='fu'>mutate</span><span class='op'>(</span>date <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/as.Date.html'>as.Date</a></span><span class='op'>(</span><span class='va'>date</span>, format <span class='op'>=</span> <span class='st'>"%d-%b-%y"</span><span class='op'>)</span>,</span>
<span>         month_name <span class='op'>=</span> <span class='fu'>month</span><span class='op'>(</span><span class='va'>date</span>, label <span class='op'>=</span> <span class='cn'>FALSE</span><span class='op'>)</span><span class='op'>)</span></span>
<span><span class='va'>text_stm</span> <span class='op'>&lt;-</span></span>
<span>  <span class='fu'>stm</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/pkg/stm/man/textProcessor.html'>textProcessor</a></span><span class='op'>(</span>documents <span class='op'>=</span> <span class='va'>df_stm</span><span class='op'>$</span><span class='va'>review</span>,</span>
<span>                meta <span class='op'>=</span> <span class='va'>df_stm</span>,</span>
<span>                removestopwords <span class='op'>=</span> <span class='cn'>TRUE</span>,</span>
<span>                removepunctuation <span class='op'>=</span> <span class='cn'>TRUE</span>,</span>
<span>                removenumbers <span class='op'>=</span> <span class='cn'>TRUE</span>,</span>
<span>                ucp <span class='op'>=</span> <span class='cn'>FALSE</span>,</span>
<span>                lowercase <span class='op'>=</span> <span class='cn'>TRUE</span>,</span>
<span>                stem <span class='op'>=</span> <span class='cn'>TRUE</span>,</span>
<span>                wordLengths <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>1</span>,<span class='cn'>Inf</span><span class='op'>)</span>,</span>
<span>                sparselevel <span class='op'>=</span> <span class='fl'>1</span></span>
<span>                <span class='op'>)</span> </span></code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>text_stm</span><span class='op'>$</span><span class='va'>documents</span><span class='op'>[[</span><span class='fl'>3</span><span class='op'>]</span><span class='op'>]</span></span></code></pre>
</div>
<pre><code>     [,1] [,2] [,3] [,4] [,5] [,6] [,7]  [,8]  [,9] [,10] [,11] [,12]
[1,] 2153 2168 2365 5016 5213 5482 9414 10444 10796 12246 14930 15873
[2,]    1    1    1    1    1    1    1     1     2     1     1     1
     [,13] [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22]
[1,] 16026 16566 18553 18862 19793 20446 20606 21831 22110 22951
[2,]     1     1     1     1     1     1     1     1     1     1
     [,23] [,24] [,25] [,26] [,27]
[1,] 25231 25744 26320 27641 29668
[2,]     1     1     1     1     1</code></pre>
</div>
<p>Processing the text using <code>textProcessor()</code> resulted in a different type of output. Rather than showing the words in document 3, we get an index reference to a list of vocab, and the number of times that word occurs in the document.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>prepped_text_stm</span> <span class='op'>&lt;-</span></span>
<span>  <span class='fu'>prepDocuments</span><span class='op'>(</span>documents <span class='op'>=</span> <span class='va'>text_stm</span><span class='op'>$</span><span class='va'>documents</span>,</span>
<span>                vocab <span class='op'>=</span> <span class='va'>text_stm</span><span class='op'>$</span><span class='va'>vocab</span>,</span>
<span>                meta <span class='op'>=</span> <span class='va'>text_stm</span><span class='op'>$</span><span class='va'>meta</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<p>Next, we proceed to fit the structural topic model using stm().</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='fu'>doParallel</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/pkg/doParallel/man/registerDoParallel.html'>registerDoParallel</a></span><span class='op'>(</span><span class='op'>)</span></span>
<span><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>240511</span><span class='op'>)</span></span>
<span><span class='va'>stm_model</span> <span class='op'>&lt;-</span></span>
<span>  <span class='fu'>stm</span><span class='op'>(</span>data <span class='op'>=</span> <span class='va'>prepped_text_stm</span><span class='op'>$</span><span class='va'>meta</span>,</span>
<span>      documents <span class='op'>=</span> <span class='va'>prepped_text_stm</span><span class='op'>$</span><span class='va'>documents</span>,</span>
<span>      vocab <span class='op'>=</span> <span class='va'>prepped_text_stm</span><span class='op'>$</span><span class='va'>vocab</span>,</span>
<span>      K <span class='op'>=</span> <span class='fl'>10</span>, <span class='co'># choose number of topics = 10</span></span>
<span>      prevalence <span class='op'>=</span> <span class='op'>~</span> <span class='va'>month_name</span>,</span>
<span>      seed <span class='op'>=</span> <span class='fl'>240511</span>,</span>
<span>      max.em.its <span class='op'>=</span> <span class='fl'>200</span>,</span>
<span>      init.type <span class='op'>=</span> <span class='st'>"Spectral"</span></span>
<span>  <span class='op'>)</span></span></code></pre>
</div>
</div>
<p>stm:: has a number of useful functions and plots we can explore. Let’s start with <code>labelTopics</code>.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='fu'>labelTopics</span><span class='op'>(</span><span class='va'>stm_model</span>, n <span class='op'>=</span> <span class='fl'>10</span><span class='op'>)</span></span></code></pre>
</div>
<pre><code>Topic 1 Top Words:
     Highest Prob: great, stay, hotel, beach, resort, restaur, shop, staff, locat, villag 
     FREX: friend, great, wonder, perfect, locat, beauti, amaz, everyth, fantast, excel 
     Lift: poolsour, resortpool, outstandingth, acc, shoppingoveral, dome, honoluluhawaiian, amenitiesw, eatth, elop 
     Score: great, shop, stay, beach, restaur, villag, staff, locat, love, beauti 
Topic 2 Top Words:
     Highest Prob: hilton, stay, room, hawaiian, hotel, member, properti, villag, servic, year 
     FREX: hhonor, member, honor, status, gold, custom, receiv, ago, treat, elit 
     Lift: misrepresent, segment, spg, againdamag, ali‘, brusqu, calll, card-pleas, committ, deskw 
     Score: hilton, member, honor, hawaiian, custom, manag, villag, properti, gold, receiv 
Topic 3 Top Words:
     Highest Prob: walk, shop, store, also, moana, beach, can, ala, waikiki, abc 
     FREX: moana, ala, flamingo, koi, pond, centr, penguin, mall, parrot, cream 
     Lift: areait, coffee-mak, conch, eateriesbar, fullest, israel, mt, pendant, ralph, sach 
     Score: moana, ala, shop, walk, centr, penguin, store, abc, mall, bus 
Topic 4 Top Words:
     Highest Prob: good, food, breakfast, price, bar, restaur, drink, nice, expens, servic 
     FREX: buffet, juic, pickl, drink, breakfast, pronto, steak, menu, food, averag 
     Lift: enjoyif, unappet, sitewould, pricesth, frontdesk, evolv, bedsroom, renter, pre-prepar, deplor 
     Score: food, good, breakfast, drink, bar, price, buffet, tropic, pizza, restaur 
Topic 5 Top Words:
     Highest Prob: resort, park, day, fee, get, hotel, car, charg, per, pay 
     FREX: fee, park, shuttl, car, airport, self, per, valet, charg, wifi 
     Lift: knowth, passcod, timet, voyag, hawaiistay, ot, odditi, minutescheck, offpick, groundscon 
     Score: fee, park, charg, car, per, resort, pay, rental, rent, tour 
Topic 6 Top Words:
     Highest Prob: hotel, like, just, peopl, get, go, place, dont, want, time 
     FREX: im, your, that, wont, bad, disney, vega, u, ive, theyr 
     Lift: “come, allerg, bookingscom, conundrum, gasp, hasn’t, mileag, shouldn’t, startour, micro 
     Score: like, peopl, dont, just, place, hotel, im, your, bad, go 
Topic 7 Top Words:
     Highest Prob: room, call, desk, one, told, towel, ask, us, check, day 
     FREX: sheet, fix, mainten, hair, replac, phone, stain, toilet, wall, secur 
     Lift: explicit, interview, band-aid, deodor, departurei, foolish, hastili, niceti, outright, reconnect 
     Score: told, call, room, manag, card, towel, ask, desk, phone, said 
Topic 8 Top Words:
     Highest Prob: room, tower, view, ocean, stay, rainbow, floor, diamond, alii, head 
     FREX: partial, ocean, view, corner, rainbow, th, renov, alii, floor, balconi 
     Lift: mix-, odd-numb, mightv, eleventh, noisiest, bathroomw, daystaff, unrenov, mid-august, guestroom 
     Score: tower, view, room, ocean, rainbow, floor, alii, balconi, diamond, head 
Topic 9 Top Words:
     Highest Prob: pool, beach, kid, lagoon, water, chair, waikiki, crowd, tower, resort 
     FREX: paddl, slide, board, sand, surf, kid, wave, lagoon, water, kayak 
     Lift: great-, shadether, inaround, ph, mana, clean-, makapuu, outther, getawayth, elementari 
     Score: pool, kid, beach, lagoon, chair, water, paddl, slide, rent, board 
Topic 10 Top Words:
     Highest Prob: us, check, room, time, arriv, night, day, book, got, didnt 
     FREX: flight, readi, queue, arriv, us, earli, late, holiday, australia, recept 
     Lift: timeupon, sone, didn, goodthi, usnot, pesto, thoughy, lewi, peoplecheck, wonderfulhousekeep 
     Score: us, check, arriv, flight, book, earli, got, readi, hour, wait </code></pre>
</div>
<p>Four different types of word weightings are printed with <code>labelTopics</code>: Highest Probability, FREX (words that are frequent and exclusive), Lift and Score.</p>
<p>We can also plot a summary of the 10 topics.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='va'>stm_model</span>,</span>
<span>     type <span class='op'>=</span> <span class='st'>"summary"</span>,</span>
<span>     n <span class='op'>=</span> <span class='fl'>10</span><span class='op'>)</span></span></code></pre>
</div>
<p><img src="text-analysis-in-r-tidytext-stm-quanteda_files/figure-html5/unnamed-chunk-20-1.png" width="576" /></p>
</div>
<p>Topic 1 has the highest expected topic proportions, and is somewhat similar to topics identified by LDA. Its highest probability words include: great, stay, hotel, beach, resort, restaur, shop, staff, locat, villag.</p>
<p>By changing type can take on 4 “settings” to see different plots: summary, labels, perspective and hist. Let’s explore all of them.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='va'>stm_model</span>,</span>
<span>     type <span class='op'>=</span> <span class='st'>"labels"</span>,</span>
<span>     n <span class='op'>=</span> <span class='fl'>5</span><span class='op'>)</span></span></code></pre>
</div>
<p><img src="text-analysis-in-r-tidytext-stm-quanteda_files/figure-html5/unnamed-chunk-21-1.png" width="576" /></p>
</div>
<p>type=“labels” plots the top words selected according to the chosen criteria for each selected topics.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='va'>stm_model</span>,</span>
<span>     type <span class='op'>=</span> <span class='st'>"perspective"</span>,</span>
<span>     topics <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>1</span>,<span class='fl'>3</span><span class='op'>)</span></span>
<span><span class='op'>)</span></span></code></pre>
</div>
<p><img src="text-analysis-in-r-tidytext-stm-quanteda_files/figure-html5/unnamed-chunk-22-1.png" width="576" /></p>
</div>
<p>type=“perspective” results in something that looks like a wordcloud, but it isnt. Instead, it plots two topic or topic-covariate combinations. Words are sized proportional to their use within the plotted topic-covariate combinations and oriented along the X-axis based on how much they favor one of the two configurations.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='va'>stm_model</span>,</span>
<span>     type <span class='op'>=</span> <span class='st'>"hist"</span>,</span>
<span>     topics <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>1</span>,<span class='fl'>3</span>, <span class='fl'>5</span>, <span class='fl'>7</span><span class='op'>)</span>,</span>
<span>     n <span class='op'>=</span> <span class='fl'>5</span><span class='op'>)</span></span></code></pre>
</div>
<p><img src="text-analysis-in-r-tidytext-stm-quanteda_files/figure-html5/unnamed-chunk-23-1.png" width="576" /></p>
</div>
<p>type = “hist” plots a histogram of the MAP estimates of the document-topic loadings across all documents. The median is also denoted by a dashed red line.</p>
<p>We can use the function <code>topicCorr</code> to generate a topic correlation matrix. Then, use plot() to visualize. There are 2 estimation procedures for producing correlation matrices: simple and huge. Let’s explore both.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>topic_corr_simple</span> <span class='op'>&lt;-</span></span>
<span>  <span class='fu'>topicCorr</span><span class='op'>(</span><span class='va'>stm_model</span>, </span>
<span>          method <span class='op'>=</span> <span class='st'>"simple"</span>,</span>
<span>          cutoff <span class='op'>=</span> <span class='fl'>0.01</span>,</span>
<span>          verbose <span class='op'>=</span> <span class='cn'>TRUE</span><span class='op'>)</span></span>
<span></span>
<span><span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='va'>topic_corr_simple</span><span class='op'>)</span></span></code></pre>
</div>
<p><img src="text-analysis-in-r-tidytext-stm-quanteda_files/figure-html5/unnamed-chunk-24-1.png" width="576" /></p>
</div>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>topic_corr_huge</span> <span class='op'>&lt;-</span></span>
<span>  <span class='fu'>topicCorr</span><span class='op'>(</span><span class='va'>stm_model</span>, </span>
<span>          method <span class='op'>=</span> <span class='st'>"huge"</span>,</span>
<span>          cutoff <span class='op'>=</span> <span class='fl'>0.01</span>,</span>
<span>          verbose <span class='op'>=</span> <span class='cn'>TRUE</span><span class='op'>)</span></span></code></pre>
</div>
<pre><code>Conducting the nonparanormal (npn) transformation via shrunkun ECDF....done.
Conducting Meinshausen &amp; Buhlmann graph estimation (mb)....done
Conducting rotation information criterion (ric) selection....done
Computing the optimal graph....done</code></pre>
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='va'>topic_corr_huge</span><span class='op'>)</span></span></code></pre>
</div>
<p><img src="text-analysis-in-r-tidytext-stm-quanteda_files/figure-html5/unnamed-chunk-25-1.png" width="576" /></p>
</div>
<p>There is only a slight difference between both plots. That’s likely because we have chosen K=10 for 10 topics. I suspect if we had a greater number of topics, the plots would look different.</p>
<p>On that note, stm also has a <code>searchK</code> function that computes diagnostic properties for a range of user-specified number of topics. We can use <code>plot</code> to “visualize” the “best” number of topics to use.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>stm_search_for_k</span> <span class='op'>&lt;-</span></span>
<span>  <span class='fu'>searchK</span><span class='op'>(</span>documents <span class='op'>=</span> <span class='va'>prepped_text_stm</span><span class='op'>$</span><span class='va'>documents</span>,</span>
<span>          vocab <span class='op'>=</span> <span class='va'>prepped_text_stm</span><span class='op'>$</span><span class='va'>vocab</span>,</span>
<span>          K <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>5</span>,<span class='fl'>10</span>,<span class='fl'>15</span>,<span class='fl'>20</span>,<span class='fl'>25</span>,<span class='fl'>30</span>,<span class='fl'>35</span>,<span class='fl'>40</span>,<span class='fl'>45</span>,<span class='fl'>50</span><span class='op'>)</span>,</span>
<span>          init.type <span class='op'>=</span> <span class='st'>"Spectral"</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='va'>stm_search_for_k</span><span class='op'>)</span></span></code></pre>
</div>
<p><img src="text-analysis-in-r-tidytext-stm-quanteda_files/figure-html5/unnamed-chunk-27-1.png" width="576" data-distill-preview=1 /></p>
</div>
<p>It would appear that K=25, or 25 topics is the “best” choice.</p>
<p>Another way of getting stm to “search” for the number of topics is by setting K=0 and init.type = “Spectral”. The document calls this “a more preliminary selection strategy based on work by Lee and Mimno (2014)”. It goes further to emphasize that this is by no means the “true” number of topics.</p>
<p>I have appended the code below for reference, but have not executed it as it is “computationally expensive”.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='fu'>doParallel</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/pkg/doParallel/man/registerDoParallel.html'>registerDoParallel</a></span><span class='op'>(</span><span class='op'>)</span></span>
<span><span class='fu'><a href='https://rdrr.io/r/base/Random.html'>set.seed</a></span><span class='op'>(</span><span class='fl'>240511</span><span class='op'>)</span></span>
<span><span class='va'>stm_model_chooseK</span> <span class='op'>&lt;-</span></span>
<span>  <span class='fu'>stm</span><span class='op'>(</span>documents <span class='op'>=</span> <span class='va'>prepped_text_stm</span><span class='op'>$</span><span class='va'>documents</span>,</span>
<span>      vocab <span class='op'>=</span> <span class='va'>prepped_text_stm</span><span class='op'>$</span><span class='va'>vocab</span>,</span>
<span>      K <span class='op'>=</span> <span class='fl'>0</span>, <span class='co'># choose number of topics = 10</span></span>
<span>      seed <span class='op'>=</span> <span class='fl'>240511</span>,</span>
<span>      max.em.its <span class='op'>=</span> <span class='fl'>200</span>,</span>
<span>      init.type <span class='op'>=</span> <span class='st'>"Spectral"</span></span>
<span>  <span class='op'>)</span></span></code></pre>
</div>
</div>
<p>stm is particularly useful in estimating a relationship between features found in meta-data and topics. In our example, we did not have many features apart from date. Yet, we can still engineer an additional feature <code>month_name</code> and use the function <code>estimateEffect()</code> to see the relationship between month and topics.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='co'>### Main Effects</span></span>
<span></span>
<span><span class='va'>stm_main_effects</span> <span class='op'>&lt;-</span></span>
<span>  <span class='fu'>estimateEffect</span><span class='op'>(</span><span class='fl'>1</span><span class='op'>:</span><span class='fl'>10</span> <span class='op'>~</span> <span class='va'>month_name</span>,</span>
<span>                 <span class='va'>stm_model</span>,</span>
<span>                 meta <span class='op'>=</span> <span class='va'>prepped_text_stm</span><span class='op'>$</span><span class='va'>meta</span>,</span>
<span>                 uncertainty <span class='op'>=</span> <span class='st'>"Global"</span><span class='op'>)</span> </span></code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='co'># we can plot this</span></span>
<span><span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='va'>stm_main_effects</span>,</span>
<span>     covariate <span class='op'>=</span> <span class='st'>"month_name"</span>,</span>
<span>     model <span class='op'>=</span> <span class='va'>stm_model</span>,</span>
<span>     topics <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>2</span>,<span class='fl'>3</span><span class='op'>)</span>,</span>
<span>     method <span class='op'>=</span> <span class='st'>"continuous"</span>,</span>
<span>     xlab <span class='op'>=</span> <span class='st'>"Months: January to December"</span>,</span>
<span>     main <span class='op'>=</span> <span class='st'>"How effects of Topic 2 and 3 changes by month"</span><span class='op'>)</span></span></code></pre>
</div>
<p><img src="text-analysis-in-r-tidytext-stm-quanteda_files/figure-html5/unnamed-chunk-30-1.png" width="576" /></p>
</div>
<p>Interesting, the effects of Topic 2 increases as we move from January to December, while the effects of Topic 3 decreases. Let’s see what Topic 2 and 3 are again.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='fu'>labelTopics</span><span class='op'>(</span><span class='va'>stm_model</span>, n <span class='op'>=</span> <span class='fl'>10</span>, topics <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>2</span>,<span class='fl'>3</span><span class='op'>)</span><span class='op'>)</span></span></code></pre>
</div>
<pre><code>Topic 2 Top Words:
     Highest Prob: hilton, stay, room, hawaiian, hotel, member, properti, villag, servic, year 
     FREX: hhonor, member, honor, status, gold, custom, receiv, ago, treat, elit 
     Lift: misrepresent, segment, spg, againdamag, ali‘, brusqu, calll, card-pleas, committ, deskw 
     Score: hilton, member, honor, hawaiian, custom, manag, villag, properti, gold, receiv 
Topic 3 Top Words:
     Highest Prob: walk, shop, store, also, moana, beach, can, ala, waikiki, abc 
     FREX: moana, ala, flamingo, koi, pond, centr, penguin, mall, parrot, cream 
     Lift: areait, coffee-mak, conch, eateriesbar, fullest, israel, mt, pendant, ralph, sach 
     Score: moana, ala, shop, walk, centr, penguin, store, abc, mall, bus </code></pre>
</div>
<p>What’s your interpretation? stm:: is an extensive package with lots more to explore. But, we need to move on to <code>quanteda</code>. If you need more information on stm:: visit this <a href="https://cran.r-project.org/web/packages/stm/vignettes/stmVignette.pdf">link</a>.</p>
<h3 id="topic-modeling-using-quanteda">Topic Modeling using quanteda</h3>
<p>We did not learn about quanteda in Module 5. There is an excellent <a href="https://tutorials.quanteda.io/">tutorial</a> which I am using to learn about the functionalities of the package. There is so much to unpack - I think I will need to write up another blog post about <code>quanteda</code>.</p>
<p><code>quanteda</code> has a simple and powerful companion package for loading texts: readtext. Let’s make use of it.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>df_quanteda</span> <span class='op'>&lt;-</span><span class='fu'>readtext</span><span class='fu'>::</span><span class='fu'><a href='https://rdrr.io/pkg/readtext/man/readtext.html'>readtext</a></span><span class='op'>(</span><span class='st'>"hotel_reviews.csv"</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<p>Wow, it even created a doc_id for each document. Nicely done. However, I notice some errors. For example “’” is being replaced by “019”. I’m not sure what other errors exist. Perhaps I shall just make use of read_csv for now?</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>df_quanteda</span> <span class='op'>&lt;-</span></span>
<span>  <span class='va'>df</span> <span class='op'>%&gt;%</span> </span>
<span>  <span class='fu'>mutate</span><span class='op'>(</span>date <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/as.Date.html'>as.Date</a></span><span class='op'>(</span><span class='va'>date</span>, format <span class='op'>=</span> <span class='st'>"%d-%b-%y"</span><span class='op'>)</span>,</span>
<span>         month_name <span class='op'>=</span> <span class='fu'>month</span><span class='op'>(</span><span class='va'>date</span>, label <span class='op'>=</span> <span class='cn'>FALSE</span><span class='op'>)</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<p>Next, I will use <code>corpus()</code> to build a corpus of text. Covariates, such as date and month, can be added using <code>docvars()</code>. quanteda calls these document variables.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>text_quanteda</span> <span class='op'>&lt;-</span><span class='fu'>corpus</span><span class='op'>(</span><span class='va'>df_quanteda</span><span class='op'>$</span><span class='va'>review</span><span class='op'>)</span></span>
<span><span class='fu'>docvars</span><span class='op'>(</span><span class='va'>text_quanteda</span>, <span class='st'>"date"</span><span class='op'>)</span> <span class='op'>&lt;-</span> <span class='va'>df_quanteda</span><span class='op'>$</span><span class='va'>date</span></span>
<span><span class='fu'>docvars</span><span class='op'>(</span><span class='va'>text_quanteda</span>, <span class='st'>"month_name"</span><span class='op'>)</span> <span class='op'>&lt;-</span> <span class='va'>df_quanteda</span><span class='op'>$</span><span class='va'>month_name</span></span></code></pre>
</div>
</div>
<p>Let’s take a look at a <code>summary()</code> of <code>text_quanteda</code>.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='fu'><a href='https://rdrr.io/r/base/summary.html'>summary</a></span><span class='op'>(</span><span class='va'>text_quanteda</span>, n<span class='op'>=</span><span class='fl'>10</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/base/print.html'>print</a></span><span class='op'>(</span><span class='op'>)</span></span></code></pre>
</div>
<pre><code>Corpus consisting of 12293 documents, showing 10 documents:

   Text Types Tokens Sentences       date month_name
  text1    51     66         7 2018-08-02          8
  text2   128    267        18 2018-05-27          5
  text3    38     50         4 2018-08-02          8
  text4   100    137         5 2018-08-02          8
  text5   125    212         9 2018-08-02          8
  text6    78    114        11 2018-08-02          8
  text7    41     53         1 2018-08-01          8
  text8   169    288        12 2018-08-01          8
  text9    68     90         5 2018-08-01          8
 text10   376    774        42 2018-08-01          8</code></pre>
</div>
<p>That’s pretty cool. Not to mention FAST! Using the corpus function, we already have some preliminary information on the number of tokens and sentences from each document. Perhaps we would like to find the “most wordy” review. Or the least wordy review. Can that be done? Yes!</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>token_info</span> <span class='op'>&lt;-</span></span>
<span>  <span class='va'>text_quanteda</span> <span class='op'>%&gt;%</span> </span>
<span>  <span class='fu'><a href='https://rdrr.io/r/base/summary.html'>summary</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'>%&gt;%</span> </span>
<span>  <span class='fu'>as_tibble</span><span class='op'>(</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>token_info</span><span class='op'>[</span><span class='fu'><a href='https://rdrr.io/r/base/which.min.html'>which.max</a></span><span class='op'>(</span><span class='va'>token_info</span><span class='op'>$</span><span class='va'>Tokens</span><span class='op'>)</span>,<span class='op'>]</span> <span class='co'># document or review 82 is the most wordy</span></span></code></pre>
</div>
<pre><code># A tibble: 1 × 6
  Text   Types Tokens Sentences date       month_name
  &lt;chr&gt;  &lt;int&gt;  &lt;int&gt;     &lt;int&gt; &lt;date&gt;          &lt;dbl&gt;
1 text82   428    971        33 2018-07-15          7</code></pre>
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>token_info</span><span class='op'>[</span><span class='fu'><a href='https://rdrr.io/r/base/which.min.html'>which.min</a></span><span class='op'>(</span><span class='va'>token_info</span><span class='op'>$</span><span class='va'>Tokens</span><span class='op'>)</span>,<span class='op'>]</span> <span class='co'># document or review 28 is the least wordy</span></span></code></pre>
</div>
<pre><code># A tibble: 1 × 6
  Text   Types Tokens Sentences date       month_name
  &lt;chr&gt;  &lt;int&gt;  &lt;int&gt;     &lt;int&gt; &lt;date&gt;          &lt;dbl&gt;
1 text28    31     33         1 2018-07-24          7</code></pre>
</div>
<p>Perhaps we only want to take a look at documents in February.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>text_quanteda</span> <span class='op'>%&gt;%</span> </span>
<span>  <span class='fu'>corpus_subset</span><span class='op'>(</span><span class='va'>month_name</span> <span class='op'>==</span> <span class='fl'>2</span><span class='op'>)</span> <span class='op'>%&gt;%</span> </span>
<span>  <span class='fu'><a href='https://rdrr.io/r/base/summary.html'>summary</a></span><span class='op'>(</span>n<span class='op'>=</span><span class='fl'>10</span><span class='op'>)</span></span></code></pre>
</div>
<pre><code>Corpus consisting of 876 documents, showing 10 documents:

    Text Types Tokens Sentences       date month_name
 text614   178    301         7 2018-02-28          2
 text615   149    249        19 2018-02-27          2
 text616    41     56         3 2018-02-27          2
 text617   111    166        10 2018-02-26          2
 text618    40     48         1 2018-02-26          2
 text619   124    188        10 2018-02-26          2
 text620   144    262        12 2018-02-25          2
 text621   187    343        21 2018-02-25          2
 text622   330    817        34 2018-02-24          2
 text623    98    165         6 2018-02-23          2</code></pre>
</div>
<p>There are many more corpus_* related functions to explore. But for now, let’s move on to the next step of tokenizing the text. For that, we can use the function <code>tokens()</code>.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>tokens_quanteda</span> <span class='op'>&lt;-</span></span>
<span>  <span class='va'>text_quanteda</span> <span class='op'>%&gt;%</span> </span>
<span>  <span class='fu'>tokens</span><span class='op'>(</span></span>
<span>    what <span class='op'>=</span> <span class='st'>"word"</span>,</span>
<span>    remove_punct <span class='op'>=</span> <span class='cn'>TRUE</span>,</span>
<span>    remove_numbers <span class='op'>=</span> <span class='cn'>TRUE</span>,</span>
<span>    remove_separators <span class='op'>=</span> <span class='cn'>TRUE</span>,</span>
<span>    verbose <span class='op'>=</span> <span class='cn'>TRUE</span></span>
<span>  <span class='op'>)</span></span></code></pre>
</div>
</div>
<p>Next, we can remove stopwords using <code>tokens_remove()</code> function. Thereafter, let’s take a look at document 3.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>tokens_quanteda_no_stopwords</span> <span class='op'>&lt;-</span></span>
<span>  <span class='fu'>tokens_remove</span><span class='op'>(</span><span class='va'>tokens_quanteda</span>, <span class='fu'>stopwords</span><span class='op'>(</span><span class='st'>"english"</span><span class='op'>)</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>tokens_quanteda_no_stopwords</span><span class='op'>[</span><span class='fl'>3</span><span class='op'>]</span></span></code></pre>
</div>
<pre><code>Tokens consisting of 1 document and 2 docvars.
text3 :
 [1] &quot;Awesome&quot;    &quot;place&quot;      &quot;attentive&quot;  &quot;friendly&quot;   &quot;staff&quot;     
 [6] &quot;stunning&quot;   &quot;views&quot;      &quot;Plenty&quot;     &quot;choices&quot;    &quot;food&quot;      
[11] &quot;reasonable&quot; &quot;expensive&quot; 
[ ... and 16 more ]</code></pre>
</div>
<p><code>quanteda</code> has many more functions to explore. For example, <code>kwic()</code> allows you to search for keywords and see what context they are being used. Let’s do a search for “food” and “expensive”</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='fu'>kwic</span><span class='op'>(</span><span class='va'>tokens_quanteda_no_stopwords</span>,</span>
<span>     pattern <span class='op'>=</span> <span class='st'>"food"</span><span class='op'>)</span> <span class='op'>%&gt;%</span> </span>
<span>  <span class='fu'><a href='https://rdrr.io/r/utils/head.html'>head</a></span><span class='op'>(</span><span class='op'>)</span></span></code></pre>
</div>
<pre><code>Keyword-in-context with 6 matches.                                                                  
   [text3, 10]        staff stunning views Plenty choices | food |
  [text28, 16] York diner Italian restaurant.Good quality | food |
  [text29, 45]             need take cab stayed timeshare | Food |
 [text35, 104]    relatively reasonable cost spa services | Food |
 [text35, 167]             you’ll see there’s much around | food |
  [text40, 12]         great hotel beach close center.The | food |
                                               
 reasonable expensive Hawaii nothing cheap     
 reasonable prices.The fireworks display missed
 prices double triple mainland crowded         
 suite kitchen just snacks wasn’t              
 entertainment activities it’ll seem like      
 good.We return sure just loved                </code></pre>
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='fu'>kwic</span><span class='op'>(</span><span class='va'>tokens_quanteda_no_stopwords</span>,</span>
<span>     pattern <span class='op'>=</span> <span class='st'>"expensive"</span><span class='op'>)</span> <span class='op'>%&gt;%</span> </span>
<span>  <span class='fu'><a href='https://rdrr.io/r/utils/head.html'>head</a></span><span class='op'>(</span><span class='op'>)</span></span></code></pre>
</div>
<pre><code>Keyword-in-context with 6 matches.                                                            
  [text3, 12]         views Plenty choices food reasonable |
  [text5, 74] staff friendly.As expected hotel restaurants |
  [text11, 8]                    just ok rooms basic quite |
 [text25, 42]                   away Price vs Quality show |
 [text27, 23]              crowds head away main beach.Can |
 [text29, 34]         shops restaurants Car rental parking |
                                                     
 expensive | Hawaii nothing cheap Close many         
 expensive | nice Starbucks property easy walk       
 expensive | get family great time Also              
 expensive | compared Polynesian Cultural center Cost
 expensive | location everything                     
 expensive | can walk grocery stores otherwise       </code></pre>
</div>
<p>You can also search by phrases. Let’s try “expensive food”.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='fu'>kwic</span><span class='op'>(</span><span class='va'>tokens_quanteda_no_stopwords</span>,</span>
<span>     pattern <span class='op'>=</span> <span class='fu'>phrase</span><span class='op'>(</span><span class='st'>"expensive food"</span><span class='op'>)</span>,</span>
<span>     window <span class='op'>=</span> <span class='fl'>5</span><span class='op'>)</span> <span class='op'>%&gt;%</span> </span>
<span>  <span class='fu'><a href='https://rdrr.io/r/utils/head.html'>head</a></span><span class='op'>(</span><span class='op'>)</span></span></code></pre>
</div>
<pre><code>Keyword-in-context with 6 matches.                                                                  
   [text49, 48:49]      dinner restaurants typical Hawaii resort |
  [text280, 79:80]          towers pools always busy restaurants |
    [text511, 1:2]                                               |
 [text1098, 41:42]      meant waiting line everything everything |
 [text1180, 42:43]                     high rise towers much day |
 [text1218, 68:69] day disappointing dinning establishments site |
                                                    
 expensive food | drinks good We’re hotel shopping  
 expensive food | mediocre room next stage live     
 Expensive food | great service great check process 
 expensive food | self parking $ night check        
 Expensive food | $ hire kayak hour walk            
 expensive food | provided group charged large group</code></pre>
</div>
<p>Lastly, you can use <code>token_ngrams()</code> to generate “ngrams”.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>tokens_quanteda_ngrams</span> <span class='op'>&lt;-</span></span>
<span>  <span class='fu'>tokens_ngrams</span><span class='op'>(</span><span class='va'>tokens_quanteda_no_stopwords</span>, n <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>1</span><span class='op'>:</span><span class='fl'>3</span><span class='op'>)</span><span class='op'>)</span></span>
<span><span class='fu'><a href='https://rdrr.io/r/utils/head.html'>head</a></span><span class='op'>(</span><span class='va'>tokens_quanteda_ngrams</span><span class='op'>[[</span><span class='fl'>3</span><span class='op'>]</span><span class='op'>]</span>, <span class='fl'>10</span><span class='op'>)</span></span></code></pre>
</div>
<pre><code> [1] &quot;Awesome&quot;   &quot;place&quot;     &quot;attentive&quot; &quot;friendly&quot;  &quot;staff&quot;    
 [6] &quot;stunning&quot;  &quot;views&quot;     &quot;Plenty&quot;    &quot;choices&quot;   &quot;food&quot;     </code></pre>
</div>
<p>Within quanteda, what we commonly reference as a document term matrix is called a document feature matrix. Quite aptly, the function <code>dfm()</code> is used to generate a document feature matrix from a tokens object.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>quanteda_dfm</span> <span class='op'>&lt;-</span></span>
<span>  <span class='fu'>dfm</span><span class='op'>(</span><span class='va'>tokens_quanteda_no_stopwords</span>,</span>
<span>      tolower <span class='op'>=</span> <span class='cn'>TRUE</span>,</span>
<span>      verbose <span class='op'>=</span> <span class='cn'>TRUE</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<p>Wow, that was blazing fast. It was done in 0.26 seconds. We can use <code>topfeatures</code> to examine the top features.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='fu'>topfeatures</span><span class='op'>(</span><span class='va'>quanteda_dfm</span>, n<span class='op'>=</span><span class='fl'>10</span><span class='op'>)</span></span></code></pre>
</div>
<pre><code>  room  hotel  beach  tower resort  great hilton   stay    one   view 
 16478  13301  12034  10737  10576   9264   8237   7703   6718   6706 </code></pre>
</div>
<p>“Room” is a top feature with 16,478 occurrences. What if we wanted to know how in how many documents does it occur?</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='fu'>topfeatures</span><span class='op'>(</span><span class='va'>quanteda_dfm</span>, n<span class='op'>=</span><span class='fl'>10</span>, scheme <span class='op'>=</span> <span class='st'>"docfreq"</span><span class='op'>)</span></span></code></pre>
</div>
<pre><code>  room  beach  hotel  tower  great   stay resort hilton stayed   view 
  7138   6680   6440   6091   5544   5215   5197   4918   4891   4425 </code></pre>
</div>
<p>As <code>quanteda</code> doesn’t implement LDA, we need to install the <code>seededlda::</code> package to implement LDA.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>quanteda_lda_model</span> <span class='op'>&lt;-</span></span>
<span>  <span class='fu'>textmodel_lda</span><span class='op'>(</span><span class='va'>quanteda_dfm</span>, k <span class='op'>=</span> <span class='fl'>10</span>, verbose <span class='op'>=</span> <span class='cn'>TRUE</span>, max_iter <span class='op'>=</span> <span class='fl'>1000</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<p>You can use <code>terms()</code> to extract the top terms for each topic.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='fu'><a href='https://rdrr.io/r/stats/terms.html'>terms</a></span><span class='op'>(</span><span class='va'>quanteda_lda_model</span>, n <span class='op'>=</span><span class='fl'>10</span><span class='op'>)</span></span></code></pre>
</div>
<pre><code>      topic1        topic2   topic3  topic4       topic5    topic6   
 [1,] &quot;beach&quot;       &quot;pool&quot;   &quot;room&quot;  &quot;food&quot;       &quot;tower&quot;   &quot;$&quot;      
 [2,] &quot;hotel&quot;       &quot;kids&quot;   &quot;us&quot;    &quot;breakfast&quot;  &quot;room&quot;    &quot;resort&quot; 
 [3,] &quot;restaurants&quot; &quot;people&quot; &quot;check&quot; &quot;good&quot;       &quot;view&quot;    &quot;day&quot;    
 [4,] &quot;waikiki&quot;     &quot;beach&quot;  &quot;hotel&quot; &quot;bar&quot;        &quot;ocean&quot;   &quot;per&quot;    
 [5,] &quot;resort&quot;      &quot;nice&quot;   &quot;desk&quot;  &quot;great&quot;      &quot;rainbow&quot; &quot;fee&quot;    
 [6,] &quot;shopping&quot;    &quot;place&quot;  &quot;told&quot;  &quot;restaurant&quot; &quot;stayed&quot;  &quot;parking&quot;
 [7,] &quot;great&quot;       &quot;pools&quot;  &quot;time&quot;  &quot;also&quot;       &quot;pool&quot;    &quot;room&quot;   
 [8,] &quot;shops&quot;       &quot;just&quot;   &quot;get&quot;   &quot;tropics&quot;    &quot;floor&quot;   &quot;get&quot;    
 [9,] &quot;walk&quot;        &quot;hotel&quot;  &quot;one&quot;   &quot;$&quot;          &quot;stay&quot;    &quot;pay&quot;    
[10,] &quot;pools&quot;       &quot;resort&quot; &quot;front&quot; &quot;abc&quot;        &quot;diamond&quot; &quot;free&quot;   
      topic7     topic8      topic9     topic10 
 [1,] &quot;hilton&quot;   &quot;great&quot;     &quot;room&quot;     &quot;beach&quot; 
 [2,] &quot;hotel&quot;    &quot;staff&quot;     &quot;tower&quot;    &quot;hotel&quot; 
 [3,] &quot;like&quot;     &quot;stay&quot;      &quot;one&quot;      &quot;lagoon&quot;
 [4,] &quot;stay&quot;     &quot;hilton&quot;    &quot;bed&quot;      &quot;can&quot;   
 [5,] &quot;property&quot; &quot;hotel&quot;     &quot;bathroom&quot; &quot;see&quot;   
 [6,] &quot;hawaiian&quot; &quot;village&quot;   &quot;beds&quot;     &quot;go&quot;    
 [7,] &quot;village&quot;  &quot;resort&quot;    &quot;floor&quot;    &quot;also&quot;  
 [8,] &quot;just&quot;     &quot;beautiful&quot; &quot;night&quot;    &quot;one&quot;   
 [9,] &quot;one&quot;      &quot;friendly&quot;  &quot;door&quot;     &quot;car&quot;   
[10,] &quot;time&quot;     &quot;hawaiian&quot;  &quot;two&quot;      &quot;island&quot;</code></pre>
</div>
<p>The function <code>topic()</code> allows you to see the likelihood that each document “talks about” which topic. For exmaple, document or text1 most likely “talks about” topic1.</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='fu'>topics</span><span class='op'>(</span><span class='va'>quanteda_lda_model</span><span class='op'>)</span> <span class='op'>%&gt;%</span> <span class='fu'><a href='https://rdrr.io/r/utils/head.html'>head</a></span><span class='op'>(</span><span class='fl'>20</span><span class='op'>)</span></span></code></pre>
</div>
<pre><code> text1  text2  text3  text4  text5  text6  text7  text8  text9 text10 
topic1 topic2 topic1 topic3 topic9 topic2 topic8 topic7 topic7 topic2 
text11 text12 text13 text14 text15 text16 text17 text18 text19 text20 
topic2 topic1 topic8 topic2 topic1 topic3 topic5 topic7 topic2 topic8 
10 Levels: topic1 topic2 topic3 topic4 topic5 topic6 ... topic10</code></pre>
</div>
<p><code>quanteda</code> is also able to perform naive bayes classification and regression classification. However, the data that we have is not suitable for this purpose.</p>
<p>Wow, that was a very very long post. quanteda is quite interesting. I think I’m going to look for a dataset where I can use it to make some predictions. It is also able to perform sentiment analysis - perhaps use to to analyze my Whatsapp messages. That would be kinda cool.</p>
<p>Thanks for reading!</p>
<div class="layout-chunk" data-layout="l-body-outset">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='co'>#save.image("hotel_reviews.RData")</span></span></code></pre>
</div>
</div>
<div class="sourceCode" id="cb27"><pre class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>


<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom"></div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
